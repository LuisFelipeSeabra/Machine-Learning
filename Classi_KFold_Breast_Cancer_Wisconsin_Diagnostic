# -*- coding: utf-8 -*-
"""
Trata-se de um dataset de Diagnóstico do câncer de mama em Wisconsin.

"""

#importação da base
import pandas as pd
base = pd.read_csv('data.csv')

import numpy as np

#########################Tratamento dos dados#####################################

#Alterar variáveis categóricas em numéricas
def diagnosis(s):
    if s == 'M':
       return 1
    elif s == 'B':
        return 0
    
    
base['diagnosis'] = base['diagnosis'].apply(diagnosis)


base.columns


#exclui coluna B_Stance
#base.drop(base['B_Stance'], axis = 0) # não funcionou?????
del base['Unnamed: 32']
del base['id']



#excluindo linhas que possuem valores nulos
base = base.dropna(axis = 0,how = 'any')

#criando nova coluna
base['diagnosis2'] = base['diagnosis']
del base['diagnosis']
base.rename(columns={'diagnosis2':'diagnosis'}, inplace = True)

#----------------------------------------------

#divisão da base em previsores e classe
previsores = base.iloc[:,0:30].values
classe = base.iloc[:,30].values


#escalonamento- deixar os valores em esclas parecidas -> melhor desempenho
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
previsores = scaler.fit_transform(previsores)

from sklearn.metrics import accuracy_score

#Resultado (REGRESSÂO LOGISTICA)
from sklearn.linear_model import LogisticRegression
#aplicação do algorítmo (RANDOM FOREST)
from sklearn.ensemble import RandomForestClassifier
#importação para (NAIVE BAYES)
from sklearn.naive_bayes import GaussianNB
# importação da bibliotca(KNN)
from sklearn.neighbors import KNeighborsClassifier
# aplicando o algorítimo (ARVORE) 
from sklearn.tree import DecisionTreeClassifier
"""
#Resultado (REDES NEURAIS KERAS)
from  tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
"""
from sklearn.model_selection import StratifiedKFold
kfold = StratifiedKFold(n_splits = 10 , shuffle = True, random_state = 0)
matriz = []

resultados1_REGLOG = []
resultados1_RF = []
resultados1_NB = []
resultados1_KNN = []
resultados1_ARV = []
resultados1_KERAS = []
for indice_treinamento, indice_teste in kfold.split(previsores, np.zeros(shape =(previsores.shape[0],1))):
        #Resultado (REGRESSÂO LOGISTICA)
        classificador_REGLOG = LogisticRegression(random_state=1)
        classificador_REGLOG.fit(previsores[indice_treinamento],classe[indice_treinamento])
        previsoes_REGLOG = classificador_REGLOG.predict(previsores[indice_teste])
        precisao_REGLOG = accuracy_score(classe[indice_teste],previsoes_REGLOG)
        resultados1_REGLOG.append(precisao_REGLOG)
        #Resultado (RANDOM FOREST))
        classificador_RF = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')
        classificador_RF.fit(previsores[indice_treinamento],classe[indice_treinamento])
        previsoes_RF = classificador_RF.predict(previsores[indice_teste])
        precisao_RF = accuracy_score(classe[indice_teste],previsoes_RF)
        resultados1_RF.append(precisao_RF)
        #importação para (NAIVE BAYES)
        classificador_NB =GaussianNB()
        classificador_NB.fit(previsores[indice_treinamento],classe[indice_treinamento])
        previsoes_NB = classificador_NB.predict(previsores[indice_teste])
        precisao_NB = accuracy_score(classe[indice_teste],previsoes_NB)
        resultados1_NB.append(precisao_NB)
        #importação para (KNN)
        classificador_KNN = KNeighborsClassifier(n_neighbors=5,metric='minkowski',  p=2)
        classificador_KNN.fit(previsores[indice_treinamento],classe[indice_treinamento])
        previsoes_KNN = classificador_KNN.predict(previsores[indice_teste])
        precisao_KNN = accuracy_score(classe[indice_teste],previsoes_KNN)
        resultados1_KNN.append(precisao_KNN)
        #importação para (ARVORE) 
        classificador_ARV = DecisionTreeClassifier(criterion = 'entropy', random_state=0)
        classificador_ARV.fit(previsores[indice_treinamento],classe[indice_treinamento])
        previsoes_ARV = classificador_ARV.predict(previsores[indice_teste])
        precisao_ARV= accuracy_score(classe[indice_teste],previsoes_ARV)
        resultados1_ARV.append(precisao_ARV)
        """  
        #importação(REDES NEURAIS KERAS)
        classificador_KERAS = Sequential()
        classificador_KERAS.add(Dense(units = 5, activation = 'relu', input_dim = 9)) #imput_dim -> neurônios na camada de entrada
        classificador_KERAS.add(Dense(units = 5, activation = 'relu', ))
        classificador_KERAS.add(Dense(units = 1, activation = 'sigmoid'))
        classificador_KERAS.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])
        classificador_KERAS.fit(previsores[indice_treinamento],classe[indice_treinamento], batch_size = 10, nb_epoch = 10)
        previsao_KERAS = classificador_KERAS.predict(previsores[indice_teste])
        precisao_KERAS = accuracy_score(classe[indice_teste],previsao_KERAS)
        resultados1_KERAS.append(precisao_KERAS)
        """
        
        
resultados1_REGLOG = np.asarray(resultados1_REGLOG)
media_REGLOG = resultados1_REGLOG.mean()
resultados1_RF = np.asarray(resultados1_RF)
media_RF = resultados1_RF.mean()  
resultados1_NB = np.asarray(resultados1_NB)
media_NB = resultados1_NB.mean()  
resultados1_KNN = np.asarray(resultados1_KNN)
media_KNN = resultados1_KNN.mean()  
resultados1_ARV = np.asarray(resultados1_ARV)
media_ARV = resultados1_ARV.mean() 
"""
resultados1_KERAS = np.asarray(resultados1_KERAS)
media_KERAS = resultados1_KERAS.mean() 
"""

